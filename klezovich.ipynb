{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jk.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81Ll0gCxDIE"
      },
      "source": [
        "Задание 1\n",
        "\n",
        "Отчистите текст от мусора (тэгов, хешей и тп) с помощью регулярных выражений. Постарайтесь убрать весь мусор, но если что-то удалить не получается, то не мучайтесь. Главное, чтобы мусор не проявлялся в результатах следующих заданий."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrFhkRbCyO8n"
      },
      "source": [
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4odyWdfxBWG"
      },
      "source": [
        "with open(\"zhivago.txt\", encoding=\"utf-8\") as f:\n",
        "  zhivago = f.read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnQ4ltCuxmN4",
        "outputId": "b69f6017-a2eb-4567-e8cd-5202ad0136c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def clean(text):\n",
        "  m1 = re.compile('<binary.*?</binary>', re.DOTALL)\n",
        "  textq = re.sub(m1, '', text)\n",
        "  m2 = re.compile('<.*?>')\n",
        "  clean_text = re.sub(m2, ' ', textq)\n",
        "  return clean_text\n",
        "\n",
        "clean(zhivago)[-300:]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ты,  Ко мне на суд, как баржи каравана,  Столетья поплывут из темноты».   \\n        Примечания \\n \\n\\n   1  \\n В восторге.  (Здесь и далее с французского.)  \\n \\n   2  \\n Большой круг! Китайская цепочка! \\n \\n   3  \\n Вальс, пожалуйста! \\n \\n   4  \\n На три счета, на два счета. \\n \\n   5  \\n Шиворот-навыворот. \\n  \\n '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBrDSNvI1onk"
      },
      "source": [
        "Задание 2.\n",
        "\n",
        "Приведите очищенный текст к нижнему регистру, удалите все знаки пунктуации, разделите на предложения библиотекой rusenttokenize, токенизируйте библиотекой razdel_tokenize. \n",
        "Ответьте на следующие вопросы:\n",
        "1) есть ли в тексте повторяющиеся корректные предложения? если да то какие? (если находится мусор то вернитесь к заданию 1 и постарайтесь избавиться от него)\n",
        "2) какой самый частотный токен в тексте длиннее 6 символов?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWUbPiXv3FoL",
        "outputId": "0530baee-617d-409f-9043-58f67218f33e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install rusenttokenize"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rusenttokenize\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Installing collected packages: rusenttokenize\n",
            "Successfully installed rusenttokenize-0.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2nJWiWZ4tJ-",
        "outputId": "d1470ce7-bc2b-4a4b-a99b-7a5eeaccd527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install razdel"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miIXkW133OKK",
        "outputId": "1de56db4-2645-462a-f754-188f5037db65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from rusenttokenize import ru_sent_tokenize\n",
        "\n",
        "all_sentences = ru_sent_tokenize(clean(zhivago))\n",
        "\n",
        "ru_sent_tokenize(clean(zhivago))[:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Борис  Леонидович  Пастернак  \\n Доктор Живаго \\n  «Доктор Живаго» - итоговое произведение Бориса Пастернака, книга всей его жизни.',\n",
              " 'Этот роман принес его автору мировую известность и Нобелевскую премию, присуждение которой обернулось для поэта оголтелой политической травлей, обвинениями в «измене Родине» и в результате стоило ему жизни.',\n",
              " '«Доктор Живаго» - роман, сама ткань которого убедительнее свидетельствует о чуде, чем все размышления доктора и обобщения автора.',\n",
              " 'Человек, который так пишет, бесконечно много пережил и передумал, и главные его чувства на свете  - восхищенное умиление и слезное сострадание; конечно, есть в его мире место и презрению, и холодному отстранению  - но не в них суть.',\n",
              " 'Роман Пастернака  - оплакивание прежних заблуждений и их жертв; те, кто не разделяет молитвенного восторга перед миром, достойны прежде всего жалости.',\n",
              " 'Перечитывать «Доктора Живаго» стоит именно тогда, когда кажется, что жить не стоит.',\n",
              " 'Тогда десять строк из этого романа могут сделать то же, что делает любовь в одном из стихотворений доктора:  «Жизнь вернулась так же беспричинно, как когда-то странно прервалась» .',\n",
              " 'ru        Litres Downloader   Litres Downloader \\n 17.04.2008  litres.ru  litres-134194  1.0       \\n  Борис Пастернак \\n Доктор Живаго \\n    И ДЫШАТ ПОЧВА И СУДЬБА \\n   Спустя два года после завершения романа «Доктор Живаго» Борис Пастернак писал: \\n  «Я думаю, несмотря на привычность всего того, что продолжает стоять перед нашими глазами и что мы продолжаем слышать и читать, ничего этого больше нет, это уже прошло и состоялось, огромный, неслыханных сил стоивший период закончился и миновал.',\n",
              " 'Освободилось безмерно большое, покамест пустое и не занятое место для нового и еще не бывалого, для того, что будет угадано чьей-либо гениальной независимостью и свежестью, для того, что внушит и подскажет жизнь новых чисел и дней.',\n",
              " 'Сейчас мукою художников будет не то, признаны ли они и признаны ли будут застаивающейся, запоздалой политической современностью или властью, но неспособность совершенно оторваться от понятий, ставших привычными, забыть навязывающиеся навыки, нарушить непрерывность.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYVWBsiR1xKp"
      },
      "source": [
        "def normalize(text):\n",
        "  words = []\n",
        "  for word in text.split():\n",
        "    word = ''.join([el for el in word if el.isalnum()])\n",
        "    word = word.lower()\n",
        "    words.append(word)\n",
        "  return ' '.join(words)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIyM_XYg5TN8",
        "outputId": "71c01e1f-d2c7-48c2-a4ec-06c907005dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from razdel import tokenize\n",
        "\n",
        "all_tokens = []\n",
        "for sent in all_sentences:\n",
        "  tokens = [el.text for el in list(tokenize(normalize(sent)))]\n",
        "  all_tokens.extend(tokens)\n",
        "\n",
        "print(all_tokens[:10])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['борис', 'леонидович', 'пастернак', 'доктор', 'живаго', 'доктор', 'живаго', 'итоговое', 'произведение', 'бориса']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpEqCJI75-5U"
      },
      "source": [
        "1) есть ли в тексте повторяющиеся корректные предложения? если да то какие?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uEjjGej6Dec",
        "outputId": "d4ef2503-ac7b-4524-cb52-2496edb797cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "dubled_sents = [item for item, count in Counter(all_sentences).items() if count > 1]\n",
        "print(len(dubled_sents))\n",
        "for el in dubled_sents[-20:]:\n",
        "  print(el)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130\n",
            "Что ты делаешь?\n",
            "Как ты думаешь?\n",
            "Хорошо.\n",
            "Завтра утром...\n",
            "Лара!\n",
            "Уехали.\n",
            "Он открыл глаза.\n",
            "– Виноват.\n",
            "Ну да!\n",
            "Больше я ее не видел.\n",
            "Как я выжил?\n",
            "Сомкнутые веки.\n",
            "Выси.\n",
            "Облака.\n",
            "Воды.\n",
            "Броды.\n",
            "Реки.\n",
            "Годы и века.\n",
            "Свеча горела на столе,  Свеча горела.\n",
            "Светало.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pry_dMDo8PzE"
      },
      "source": [
        "2) какой самый частотный токен в тексте длиннее 6 символов?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Se-wIJ8RQ6",
        "outputId": "e07f31f6-7fae-403e-a419-54f9ebebd2d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_counter = {}\n",
        "for item, count in Counter(all_tokens).items():\n",
        "  if len(item) > 6:\n",
        "    new_counter[item] = count\n",
        "\n",
        "for word in sorted(new_counter, key=new_counter.get, reverse=True)[:5]:\n",
        "  print(word, new_counter[word])\n",
        "\n",
        "print(\"Самый частотный токен длиной более 6 символов - \" + sorted(new_counter, key=new_counter.get, reverse=True)[0])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "андреевич 289\n",
            "несколько 115\n",
            "человек 112\n",
            "который 104\n",
            "доктора 89\n",
            "Самый частотный токен длиной более 6 символов - андреевич\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdUwWV39_Q21"
      },
      "source": [
        "Задание 3.\n",
        "\n",
        "Сделайте стемминг и найдите по несколько частотных примеров на каждый из видов ошибок:\n",
        "1) два разных слова ошибочно свелись к одинаковой основе\n",
        "3) слово не изменилось после стемминга (слово должно быть русским и длиннее 4 символов)\n",
        "\n",
        "***не делайте это задание полностью вручную, напишите правила, которые отловят потенциальные ошибки и выберите из них***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilmQz7mn_kVr"
      },
      "source": [
        "Задание 4\n",
        "\n",
        "Проанализируйте список стоп-слов из нлтк (для русского). Какие ещё слова вы бы туда добавили? (5 слов будет достаточно, не забудьте аргументировать ваш выбор)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ5f-Nux_zDO",
        "outputId": "bc5680d7-b221-4f56-f748-0a7c512abba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRZ_LFQ4_67r"
      },
      "source": [
        "stops = set(stopwords.words('russian'))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCdeKfk9AEzD"
      },
      "source": [
        "#for word in stops:\n",
        "#  print(word)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8klJVjCwAeEC"
      },
      "source": [
        "Чтобы решить, какие слова добавить в список стоп-слов, можно посмотреть самые частотные слова для нашего текста и найти разницу нашего множества частотных слов с множеством стоп-слов из нлтк"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os5oI265AFxl",
        "outputId": "9fb43e8f-a76d-4d76-c3d0-b343a30928a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "frequent_in_text = set([item for item, count in Counter(all_tokens).most_common(150)])\n",
        "\n",
        "frequent_in_text.difference(stops)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'андреевич',\n",
              " 'вместе',\n",
              " 'время',\n",
              " 'всем',\n",
              " 'дело',\n",
              " 'день',\n",
              " 'доктор',\n",
              " 'доктора',\n",
              " 'дом',\n",
              " 'дома',\n",
              " 'друг',\n",
              " 'живаго',\n",
              " 'жизни',\n",
              " 'жизнь',\n",
              " 'знаю',\n",
              " 'которые',\n",
              " 'который',\n",
              " 'лара',\n",
              " 'люди',\n",
              " 'минуту',\n",
              " 'несколько',\n",
              " 'пока',\n",
              " 'руки',\n",
              " 'своей',\n",
              " 'сказал',\n",
              " 'стал',\n",
              " 'стало',\n",
              " 'тебе',\n",
              " 'человек',\n",
              " 'чтото',\n",
              " 'это',\n",
              " 'юра',\n",
              " 'юрий',\n",
              " 'юрия'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIw8aEsFBs4m"
      },
      "source": [
        "Если не учитывать имена, то всё подходит на стоп-слова. В задании сказано выбрать 5. Пусть будут -- \"вместе\", \"это\", \"чтото\", \"тебе\", \"которые\", \"который\". Эти слова служебные, поэтому они подходят "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpbP-jY8Bs9O"
      },
      "source": [
        "Задание 5.\n",
        "\n",
        "Предобработайте текст двумя способами:\n",
        "1) лемматизируйте токены с помощью pymorphy2\n",
        "2) лемматизируйте текст с помощью mystem3 \n",
        "\n",
        "Ответьте на вопрос:\n",
        "Что в данном случае лучше для лемматизации mystem или pymorphy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsLCum23EI0k"
      },
      "source": [
        "Известно, что mystem работает медленне, но лучше, чем pymorphy для русского языка. Можно засечь время работы того и другого метода, чтобы сравнить, насколько велика потеря времени. + оценить качество работы и сравнить"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twawbw5qEal6",
        "outputId": "a07efe1f-b382-4c79-9960-174bfb1466bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install pymorphy2"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQcTW-IgFFfw"
      },
      "source": [
        "import timeit"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu1O72y5Emae"
      },
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnaPOXipEvYb",
        "outputId": "826192f5-ab9e-4b69-916e-0474529934c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%timeit\n",
        "lemmas = []\n",
        "for word in all_tokens:\n",
        "  p = morph.parse(word)[0]\n",
        "  lemmas.append(p.normal_form)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 37 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py8ptXMRFLZ1",
        "outputId": "f8fef82e-cf4e-471e-c03a-493641d6160d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(lemmas[:10])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['борис', 'леонидович', 'пастернак', 'доктор', 'живаго', 'доктор', 'живаго', 'итоговый', 'произведение', 'борис']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2IlHdeaF7vj",
        "outputId": "15bdfc46-3cba-4e87-f71a-31e701835dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install pymystem3"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymystem3 in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOyxd5zQF8yL",
        "outputId": "2b49770c-c798-4b50-e276-db7851f299dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pymystem3 import Mystem\n",
        "m = Mystem()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GptT3lxF9Mw"
      },
      "source": [
        "#start_time = timeit.default_timer()\n",
        "lemmas2 = []\n",
        "for word in all_tokens[:10]:\n",
        "  m = Mystem()\n",
        "  print(m.lemmatize(word))\n",
        "  lemmas2.append(m.lemmatize(word))\n",
        "#elapsed = timeit.default_timer() - start_time\n",
        "#elapsed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTVZ7MFOGiB5",
        "outputId": "d68fabe6-7002-4fa0-b1d0-9ef4a75cb72f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(lemmas2[:10])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}