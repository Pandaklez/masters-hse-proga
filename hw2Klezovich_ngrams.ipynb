{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "hw2Klezovich_ngrams.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pandaklez/masters-hse-proga/blob/master/hw2Klezovich_ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbLr2okFaTec"
      },
      "source": [
        "Задание 1.\n",
        "\n",
        "В тетрадке реализована биграмная языковая модель (при генерации учитывается информация только о 1 предыдущем слове). Реализуйте триграмную модель и сгенерируйте несколько текстов. Сравните их с текстами, сгенерированными биграмной моделью. \n",
        "Можно использовать те же тексты, что в семинаре, или взять какой-то другой (на английском или русском языке).  \n",
        "\n",
        "Делать это задание будет легче после прочтения первых 7 страниц вот этой главы из Журафского - https://web.stanford.edu/~jurafsky/slp3/3.pdf\n",
        "\n",
        "Я частично копирую текст семинарской тетрадки, прошу прощения за путаницу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LxiJkoxaTed"
      },
      "source": [
        "Возьмем два разных корпуса: новостной и сообщения с 2ch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gZx-SupaTed"
      },
      "source": [
        "# !!! двач не самое приятное место, большое количество текстов в этом корпусе токсичные\n",
        "dvach = open('2ch_corpus.txt').read()\n",
        "# !!! двач не самое приятное место, большое количество текстов в этом корпусе токсичные\n",
        "\n",
        "news = open('lenta.txt').read()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddJAKPkaTei"
      },
      "source": [
        "Напишем простую функцию для нормализации. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvidN2ZPbHqA",
        "outputId": "0b928892-8112-423c-b926-d5bf512e09e5"
      },
      "source": [
        "! pip install razdel"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: razdel in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt4Z9FRpaTei"
      },
      "source": [
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "import numpy as np\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG3nHu59aTej"
      },
      "source": [
        "Сравним тексты по токенам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjDL1Q_CaTej"
      },
      "source": [
        "norm_dvach = normalize(dvach)\n",
        "norm_news = normalize(news)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMsraX6QaTej",
        "outputId": "d11cd206-ce93-4c50-d92b-c40868df7f55"
      },
      "source": [
        "print(\"Длина корпуса токсичных постов в токенах -\", len(norm_dvach))\n",
        "print(\"Длина корпуса новостных текстов в токенах - \", len(norm_news))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Длина корпуса токсичных постов в токенах - 1858941\n",
            "Длина корпуса новостных текстов в токенах -  1505789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKA46ku_aTej"
      },
      "source": [
        "И по уникальным токенам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk4DTXoGaTej",
        "outputId": "b528d93a-02b9-44b7-b392-611d1b344fe1"
      },
      "source": [
        "print(\"Уникальных токенов в корпусе токсичных постов -\", len(set(norm_dvach)))\n",
        "print(\"Уникальный токенов в корпусе новостных текстов - \", len(set(norm_news)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Уникальных токенов в корпусе токсичных постов - 189515\n",
            "Уникальный токенов в корпусе новостных текстов -  116302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjdReVnaTej"
      },
      "source": [
        "Посчитаем, сколько раз встречаются слова и выведем самые частотные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1TU3UM3aTej"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U2pVYkIaTek"
      },
      "source": [
        "vocab_dvach = Counter(norm_dvach)\n",
        "vocab_news = Counter(norm_news)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swaMF2NaTek"
      },
      "source": [
        "Сравнивать употребимость конкретных слов в разных текстах в абсолютных числах неудобно. Нормализуем счётчики на размеры текстов. Так у нас получается вероятность слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlakyxAMaTek",
        "outputId": "003b6797-bc9b-4c65-f49d-9485dccc7d0a"
      },
      "source": [
        "probas_dvach = Counter({word:c/len(norm_dvach) for word, c in vocab_dvach.items()})\n",
        "probas_dvach.most_common(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 0.030066580918921042),\n",
              " ('в', 0.02628001641794979),\n",
              " ('не', 0.02506911192985684),\n",
              " ('на', 0.015955320798239428),\n",
              " ('что', 0.014345802260534357)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZhBl_-qaTek",
        "outputId": "020195f1-b504-4acd-e953-8528dc715ff6"
      },
      "source": [
        "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})\n",
        "probas_news.most_common(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('в', 0.04808907489694771),\n",
              " ('и', 0.0221080111489724),\n",
              " ('на', 0.018883123731146926),\n",
              " ('по', 0.012943380513471676),\n",
              " ('что', 0.011310349590812525)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cSAGbXuaTek"
      },
      "source": [
        "Эти вероятности уже можно использовать, чтобы ответить на вопрос - это предложение больше подходит для новостей или для анонимного форума?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnWHnJvFaTel"
      },
      "source": [
        "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'\n",
        "\n",
        "prob = Counter({'news':0, 'dvach':0})\n",
        "\n",
        "for word in normalize(phrase):\n",
        "    prob['dvach'] += probas_dvach.get(word, 0)\n",
        "    prob['news'] += probas_news.get(word, 0)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rxt2rXTaTel",
        "outputId": "28dc461d-f455-463a-e1a1-5aa584b8d08a"
      },
      "source": [
        "prob.most_common()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dvach', 0.034328147047162874), ('news', 0.014186582582287426)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26OMWPkGaTel"
      },
      "source": [
        "phrase = 'как вы смотрите эту залупу, серьезно. в чем прикол ваще это смотреть?'\n",
        "\n",
        "prob = Counter({'news':0, 'dvach':0})\n",
        "\n",
        "for word in normalize(phrase):\n",
        "    prob['dvach'] += probas_dvach.get(word, 0)\n",
        "    prob['news'] += probas_news.get(word, 0)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofkS2DgFaTel",
        "outputId": "a3e8c372-d308-485d-f64a-6362b2bcb275"
      },
      "source": [
        "prob.most_common()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('news', 0.05619313197267346), ('dvach', 0.04750823183737408)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxaroR3LaTel"
      },
      "source": [
        "Результаты получаются не очень точные. Возможно это из-за того, что мы считаем слова независимыми друг от друга. А это очевидно не так"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNNvb2ueaTel"
      },
      "source": [
        "По-хорошему вероятность последовательности нужно расчитывать по формуле полной вероятности. Но у нас не очень большие тексты и мы не можем получить вероятности для длинных фраз (их просто может не быть в текстах). Поэтому мы воспользуемся предположением Маркова и будем учитывать только предыдущее слово."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuLz_fk8aTel"
      },
      "source": [
        "Чтобы расчитать вероятность с таким предположением, нам достаточно найти количество вхождений для каждого биграмма."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5qFKUcxaTel"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# вот тут начинается интересное. \n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J1QXeTxaTel"
      },
      "source": [
        "Для того, чтобы у нас получились честные вероятности и можно было посчитать вероятность первого слова, нам нужно добавить тэг маркирующий начало предложений \\< start \\>\n",
        "\n",
        "Дальше мы попробуем сгенерировать текст, используя эти вероятности, и нам нужно будет когда-то остановится. Для этого добавим тэг окончания \\< end \\>\n",
        "\n",
        "Ну и поделим все на предложения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTxqZ2I4cOUQ",
        "outputId": "168ecdb3-e849-4d8c-e0ee-9e179c4eddac"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTZ_zCX9n-lM",
        "outputId": "953c821a-40f9-4988-dffa-6b8e5dd314c8"
      },
      "source": [
        "len(dvach)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11638405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4s7vSSeaTel"
      },
      "source": [
        "sentences_dvach = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach[:100000])]\n",
        "sentences_news = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news[:100000])]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_22wY5hmaXw",
        "outputId": "8d69ad8e-217a-4be3-b812-ee6a5bd59361"
      },
      "source": [
        "len(sentences_dvach)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1450"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD-TDLVOc86L"
      },
      "source": [
        "Вот на этом этапе к составлению биграммов я добавляю составление триграммов. Чтобы потом можно было сравнить два типа этих моделей.\n",
        "\n",
        "Так же я беру только часть предложений, потому что иначе у меня умирает память на этапе генерации текстов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjm-WdqGaTel"
      },
      "source": [
        "unigrams_dvach = Counter()\n",
        "bigrams_dvach = Counter()\n",
        "trigrams_dvach = Counter()\n",
        "\n",
        "for sentence in sentences_dvach[:10000]:\n",
        "    unigrams_dvach.update(sentence)\n",
        "    bigrams_dvach.update(ngrammer(sentence))\n",
        "    trigrams_dvach.update(ngrammer(sentence, n=3))\n",
        "\n",
        "\n",
        "unigrams_news = Counter()\n",
        "bigrams_news = Counter()\n",
        "trigrams_news = Counter()\n",
        "\n",
        "for sentence in sentences_news[:10000]:\n",
        "    unigrams_news.update(sentence)\n",
        "    bigrams_news.update(ngrammer(sentence))\n",
        "    trigrams_news.update(ngrammer(sentence, n=3))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONKWzKrOaTel",
        "outputId": "b91e8260-f93a-40e0-b386-0ec99159b871"
      },
      "source": [
        "len(unigrams_dvach)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5450"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQK6cgLUaTel",
        "outputId": "36c5d20b-f8f7-4b76-a077-dd1adab054fb"
      },
      "source": [
        "bigrams_news.most_common(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start> в', 959),\n",
              " ('<start> по', 791),\n",
              " ('<start> как', 577),\n",
              " ('риа новости', 361),\n",
              " ('как сообщает', 284),\n",
              " ('по словам', 247),\n",
              " ('<start> на', 233),\n",
              " ('об этом', 226),\n",
              " ('<start> об', 208),\n",
              " ('<start> однако', 205)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po9Av6FadKDj",
        "outputId": "60d728e7-1149-404b-8ed0-a6685c8881ff"
      },
      "source": [
        "trigrams_news.most_common(10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start> об этом', 1579),\n",
              " ('<start> по словам', 1549),\n",
              " ('сообщает риа новости', 1324),\n",
              " ('со ссылкой на', 1243),\n",
              " ('риа новости <end>', 1228),\n",
              " ('<start> кроме того', 1070),\n",
              " ('<start> как сообщает', 1064),\n",
              " ('<start> напомним что', 1006),\n",
              " ('по его словам', 899),\n",
              " ('<start> по его', 868)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVjP0at_aTel"
      },
      "source": [
        "Чтобы посчитать условную вероятность мы можем поделить количество вхождений на количество вхождений первого слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiQ7oK-faTel"
      },
      "source": [
        "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала'\n",
        "# phrase = 'как вы смотрите эту залупу, серьезно. в чем прикол ваще это смотреть?'\n",
        "prob = Counter()\n",
        "for ngram in ngrammer(['<start>'] + normalize(phrase) + ['<end>']):\n",
        "    word1, word2 = ngram.split()\n",
        "    \n",
        "    if word1 in unigrams_dvach and ngram in bigrams_dvach:\n",
        "        prob['dvach'] += np.log(bigrams_dvach[ngram]/unigrams_dvach[word1])\n",
        "    else:\n",
        "        prob['dvach'] += np.log(0.001)\n",
        "    \n",
        "    if word1 in unigrams_news and ngram in bigrams_news:\n",
        "        prob['news'] += np.log(bigrams_news[ngram]/unigrams_news[word1])\n",
        "    else:\n",
        "        prob['news'] += np.log(0.001)\n",
        "\n",
        "prob['news'] = np.exp(prob['news'])\n",
        "prob['dvach'] = np.exp(prob['dvach'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGhFPhQZaTel",
        "outputId": "00f80260-4051-4a19-ef77-30bf60621c53"
      },
      "source": [
        "prob.most_common()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('news', 3.8562170896053503e-25), ('dvach', 8.260197121507218e-38)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW5XreD9aTem"
      },
      "source": [
        "Работает получше. Мы воспользовались небольшим хаком - для слов или биграммов, которых не было у нас в словаре, прибавляли низкую вероятность. Исправить это по-нормальному - сложно, придется подробнее разбираться с вероятностями, сглаживаниями и заменой неизвестных слов. Если интрересно - в книге Журафского про это есть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2RyCMG5dgf7"
      },
      "source": [
        "Теперь попробуем посчитать условную верояность с помощью триграммов. Тут мы добавляем еще один токен `<start>` в начало. Это нужно для того, чтобы могли строить предсказания начиная с первого слова. Ведь триграмы предсказывают вероятность на основе **двух** предыдущих слов, значит перед первым и вторым словом не хватает токенов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDutmoh9dqtk"
      },
      "source": [
        "phrase = 'Технические возможности устаревшего российского судна не позволили разгрузить его у терминала''Ныть надо меньше и работать больше.'\n",
        "# phrase = 'как вы смотрите эту залупу, серьезно. в чем прикол ваще это смотреть?'\n",
        "prob = Counter()\n",
        "for ngram in ngrammer(['<start>', '<start>'] + normalize(phrase) + ['<end>'], n=3):\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    \n",
        "    if word1 in unigrams_dvach and ngram in trigrams_dvach:\n",
        "        prob['dvach'] += np.log(trigrams_dvach[ngram]/unigrams_dvach[word1])\n",
        "    else:\n",
        "        prob['dvach'] += np.log(0.001)\n",
        "    \n",
        "    if word1 in unigrams_news and ngram in trigrams_news:\n",
        "        prob['news'] += np.log(trigrams_news[ngram]/unigrams_news[word1])\n",
        "    else:\n",
        "        prob['news'] += np.log(0.001)\n",
        "\n",
        "prob['news'] = np.exp(prob['news'])\n",
        "prob['dvach'] = np.exp(prob['dvach'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx8Oek6seST2",
        "outputId": "c1ea739c-29bb-46cb-bf4a-51253af9c32b"
      },
      "source": [
        "prob.most_common()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('news', 5.5054854013773364e-45), ('dvach', 1.000000000000004e-51)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kM8pWTkNE5"
      },
      "source": [
        "Разница на 6 степеней получилась. А в биграмах была разница 13 степеней, то есть биграмы на этой задаче более разительную разницу показали почему-то."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5kdSEjwaTem"
      },
      "source": [
        "Генерируем новый текст на основне биграмов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHXRE16UaTem"
      },
      "source": [
        "matrix_dvach = np.zeros((len(unigrams_dvach), \n",
        "                   len(unigrams_dvach)))\n",
        "id2word_dvach = list(unigrams_dvach)\n",
        "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
        "\n",
        "\n",
        "for ngram in bigrams_dvach:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_dvach[word2id_dvach[word1]][word2id_dvach[word2]] =  (bigrams_dvach[ngram]/\n",
        "                                                                     unigrams_dvach[word1])\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX1QnutjaTem"
      },
      "source": [
        "# создадим матрицу вероятностей перейти из 1 слов в другое\n",
        "matrix_news = np.zeros((len(unigrams_news), \n",
        "                   len(unigrams_news)))\n",
        "\n",
        "id2word_news = list(unigrams_news)\n",
        "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
        "\n",
        "\n",
        "# вероятность расчитываем точно также\n",
        "for ngram in bigrams_news:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_news[word2id_news[word1]][word2id_news[word2]] =  (bigrams_news[ngram]/\n",
        "                                                                     unigrams_news[word1])\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2BVcYnaTem"
      },
      "source": [
        "Для генерации нам понадобится функция np.random.choice , которая выбирает случайный объект из заданных. Ещё в неё можно подать вероятность каждого объекта и она будет доставать по ним (не только максимальный по вероятности)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II17ktt_aTem"
      },
      "source": [
        "\n",
        "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knpARppZaTem",
        "outputId": "9ace10e2-a38f-4509-a110-133f7f4bc41d"
      },
      "source": [
        "print(generate(matrix_dvach, id2word_dvach, word2id_dvach).replace('<end>', '\\n'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ответ 20 не может быть программистом и сделаю это говно как там ещё чтобы разговор которого хватает \n",
            " позже всё ещё необычная мегумин \n",
            " сёма ну она не гослинговский молчаливый кун с перла но больно анальные там юно на программу нихуя что-то с нуля пропуская кучу ненужной параши python php c кодер тян \n",
            " о коля привет привет петя и хх 20 баксов миллионер ахаха в it сверхдержава блять \n",
            " а как такового но они сложные только шахматы ходят на хуй говорю когда танцоры по 90 программистов это факт против которого я хз кто не останешься \n",
            " наверное математик \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7CX0-LnaTem",
        "outputId": "30da5a37-b342-43e1-e545-2cfcc863bd5c"
      },
      "source": [
        "print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "в подписных листах если угодно вопросы финансовой политике направленном правительством москвы напоминающий самодельное взрывное устройство \n",
            " есть потери \n",
            " пленка была объявлена большая колонна отступавшая по крайней мере расследования \n",
            " а пока не прекращаютсявопреки четким требованиям верховных звонков в истории гражданской авиации аргентины \n",
            " его мнению представителей американских ученых из центральных улиц бельгийской артиллерии руководивший обороной одного из россиян во фронт \n",
            " кроме того кто сегодня что все неурядицы сейчас в очаге конфликта 250 долларов \n",
            " как сообщает сегодня по сведениям в торговом комплексе охотный ряд на своей неотъемлемой частью при чем на интервенции до 3300 рублей \n",
            " правда окраины\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEg_NClEoKal"
      },
      "source": [
        "У меня получается генерировать тексты только на очень маленьком количестве предложений, до 1000, поэтому тексты дикий отстой. Если делать больше данных, то память ложится даже в колабе. Возможно я что-то не так делаю с колабом ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ5B1DAsaTem"
      },
      "source": [
        "matrix_dvach = np.zeros((len(unigrams_dvach), \n",
        "                   len(unigrams_dvach)))\n",
        "id2word_dvach = list(unigrams_dvach)\n",
        "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
        "\n",
        "\n",
        "for ngram in trigrams_dvach:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    matrix_dvach[word2id_dvach[word1]][word2id_dvach[word2]] =  (trigrams_dvach[ngram]/\n",
        "                                                                     unigrams_dvach[word1])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPSN8FdaaTen"
      },
      "source": [
        "# создадим матрицу вероятностей перейти из 1 слов в другое\n",
        "matrix_news = np.zeros((len(unigrams_news), \n",
        "                   len(unigrams_news)))\n",
        "\n",
        "id2word_news = list(unigrams_news)\n",
        "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
        "\n",
        "\n",
        "# вероятность расчитываем точно также\n",
        "for ngram in trigrams_news:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    matrix_news[word2id_news[word1]][word2id_news[word2]] =  (trigrams_news[ngram]/\n",
        "                                                                     unigrams_news[word1])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEn-vUaIr3P8"
      },
      "source": [
        "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "s7FXG63Ar5iz",
        "outputId": "42b6ba89-03bc-4f82-dec8-acc5f551ef7e"
      },
      "source": [
        "print(generate(matrix_dvach, id2word_dvach, word2id_dvach).replace('<end>', '\\n'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-12dd45d28f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_dvach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word_dvach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id_dvach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<end>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-93eeb6aa3e13>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(matrix, id2word, word2id, n, start)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mchosen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchosen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: probabilities do not sum to 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "GFH0vQwer9mK",
        "outputId": "bc2f5fe3-7210-41aa-f0af-915101eb13b1"
      },
      "source": [
        "print(generate(matrix_news, id2word_news, word2id_news).replace('<end>', '\\n'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0a33b0447947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id_news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<end>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-93eeb6aa3e13>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(matrix, id2word, word2id, n, start)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mchosen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchosen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: probabilities do not sum to 1"
          ]
        }
      ]
    }
  ]
}